# -*- coding: utf-8 -*-
"""02_data_explore.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/168NKpho3PjtQHyJ18T_mWJx5Gq1e-54X

## **Importação Bibliotecas**
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, RobustScaler
from sklearn.ensemble import RandomForestClassifier
import textwrap

import seaborn as sns
import matplotlib.pyplot as plt

"""## **Leitura de Dados**"""

data = pd.read_csv('/content/drive/MyDrive/Proj. Laboratório de Ciência de Dados /data /clear/data_clean')

"""## **Exploração dos dados**

- **Identificar Colunas Relevantes:**

Ele encontra as colunas que não contêm números, provavelmente porque são categorias ou texto, e salva esses nomes.

- **Entender a Distribuição das Classes em algumas situações:**

## **Organização 2 - Gráfico contagem das vitórias de cada equipe em diferentes mapas do jogo.**


**Objetivo:** proporcionar uma visão visual das tendências de vitórias em contextos específicos.


- Identificação de padrões consistentes de desempenho em mapas específicos.
- Análise do desempenho de equipes e seleção estratégica de mapas.
- Apoio na tomada de decisões táticas durante torneios.
- Avaliação de rivalidades e competitividade em cenários específicos.
- Monitoramento da evolução do desempenho ao longo do tempo em diferentes mapas.
- Contribui para estratégias mais informadas e eficazes.
"""

# Criar a coluna 'match_id'
data['match_id'] = data['map'].ne(data['map'].shift()).cumsum()
data['match_id'] = data['match_id'].apply(lambda x: f'ID:{x}' if x else None)
data['match_id'] = data['match_id'].ffill()

# Agrupar por 'match_id', 't_score' e 'ct_score', e criar a coluna 'round'
agrupamento = data.groupby(['match_id', 't_score', 'ct_score']).apply(lambda x: x.assign(round=x['ct_score'] + x['t_score'] + 1)).reset_index(drop=True)

# Selecionar algumas colunas para visualizar
selected_columns = ['ct_score', 't_score', 'round']
print(agrupamento[selected_columns].head(20))

# Exibir valores únicos de 'time_left'
print(sorted(agrupamento['time_left'].unique()))

# Converter 'time_left' para tipo numérico antes de arredondar
agrupamento['time_left'] = pd.to_numeric(data['time_left'], errors='coerce')

# Arredondar 'time_left' para intervalos específicos
agrupamento['time_left'] = agrupamento['time_left'].round(-1)
bins = [25, 50, 75, 100, 125, 150, 175]
agrupamento['time_left'] = pd.cut(agrupamento['time_left'], bins, right=False, labels=bins[:-1])

# Remover duplicatas de 'time_left' para cada 'match_id' e 'round'
data_agrupado = agrupamento.groupby(['match_id', 'round']).apply(lambda x: x.drop_duplicates('time_left')).reset_index(drop=True)

# Exibir as primeiras linhas do DataFrame resultante
data_agrupado.head()

data_agrupado.columns

# Configurações para o tamanho do gráfico
plt.figure(figsize=(15, 7.5))

# Definir estilo de texto
text_style = {'size': 14, 'weight': 'bold'}

# Criar um tema padrão
standard_theme = sns.set_theme(style="whitegrid", font_scale=1.4, rc={"axes.labelsize": 14, "legend.fontsize": 14, "axes.titlesize": 14})

# Paleta de cores
ctr_fill_palette = sns.color_palette(['#084d6e', '#9b902c'])

# Evitar contagens duplicadas
dt_modificado = data_agrupado.groupby(['match_id', 'ct_score', 't_score']).apply(lambda x: x.drop_duplicates('match_id')).reset_index(drop=True)

# Plotar gráfico de barras
plt.figure(figsize=(15, 7.5))
sns.countplot(data=dt_modificado, x='map', hue='round_winner', palette='gray')
plt.title('Contagem de Partidas Ganhas por Equipe em Cada Mapa', **text_style)
plt.xlabel('Map', **text_style)
plt.ylabel('Contagem', **text_style)
plt.legend(title='Round Winner', title_fontsize=16, fontsize=14)
plt.show()

"""## **Organização 3- Distribuição das porcentagens de uso de armas e granadas em partidas**

- Os gráficos representam a distribuição das porcentagens de uso de armas em partidas de CS:GO para cada lado (T e CT).

- Construído a partir do conjunto de dados que inclui informações sobre partidas, jogadores vivos, pontuações e armas utilizadas.

- Em cada gráfico, o eixo horizontal mostra a porcentagem de uso de cada arma, enquanto o eixo vertical exibe as diferentes armas.

- Cada barra representa uma arma específica, com a altura indicando a porcentagem de vezes que a arma foi usada em relação ao total de armas do lado (T ou CT).

- O propósito do gráfico é oferecer uma visão visual das preferências de armas em contextos de jogo distintos (T e CT).

- Útil para compreender estratégias preferenciais das equipes em diferentes lados e adaptações a estratégias inimigas.

- Também auxilia na análise da evolução das escolhas de armas ao longo do tempo ou em diferentes mapas do jogo CS:GO.
"""

dt = data

# Função para criar gráficos de armas com porcentagens acima de 1%
def weapon_plot_above(column, title, fill, ylab, threshold=0.01):
    # Filtrar colunas relevantes
    weapons_data = dt.filter(regex=column)

    # Calcular porcentagens
    weapons_percentage = weapons_data.sum() / weapons_data.sum().sum()

    # Filtrar apenas as armas com porcentagem acima de 1%
    weapons_df = weapons_percentage[weapons_percentage > threshold]

    # Criar DataFrame para o gráfico
    weapons_df = pd.DataFrame({'weapons': weapons_df.index, 'percentage': weapons_df.values})

    # Ordenar porcentagens
    weapons_df = weapons_df.sort_values(by='percentage', ascending=False)

    # Plotar gráfico de barras
    plt.figure(figsize=(10, 6))
    sns.barplot(x='percentage', y='weapons', data=weapons_df, palette=[fill])

    # Configurações adicionais
    plt.title(title, fontsize=16)
    plt.xlabel('Porcentagem', fontsize=14)
    plt.ylabel(ylab, fontsize=10)

    # Incluir quebras de linha nas variáveis do eixo y
    plt.yticks(range(len(weapons_df['weapons'])), [textwrap.fill(weapon, width=20) for weapon in weapons_df['weapons']])

    plt.show()

# Criar gráfico das distribuição das porcentagens de uso de armas em partidas - Time T
weapon_plot_above(column='t_weapon_', title='Percentual de armas do lado T', fill='#9b902c', ylab='Weapons')

# Criar gráfico das distribuição das porcentagens de uso de armas em partidas - Time CT
weapon_plot_above(column='ct_weapon_', title='Percentual de armas do lado CT', fill='#084d6e', ylab='Weapons')

"""É relevante destacar que certas armas, como a Glock e a USPS, embora sejam pistolas, são predominantemente utilizadas em rodadas de eco. Rodadas de eco ocorrem quando os jogadores não possuem recursos financeiros para adquirir equipamentos primários. Além disso, essas pistolas são comumente empregadas em rodadas iniciais.

## **Classificação RandomForest para avaliar a importância das features**

> Bloco com recuo



O propósito desse código é realizar uma série de pré-processamentos nos dados e, em seguida, treinar um modelo de classificação RandomForest para avaliar a importância das features (variáveis) no contexto do conjunto de dados.

O algoritmo Random Forest é uma técnica de aprendizado de máquina que se enquadra na categoria de ensemble learning, ou seja, ele combina os resultados de vários modelos para melhorar o desempenho geral. Aqui está como o Random Forest opera:

**Amostragem Aleatória (Bagging):** O Random Forest cria várias árvores de decisão independentes, cada uma treinada em uma amostra aleatória (com substituição) dos dados de treinamento. Isso é chamado de bagging.

**Construção de Árvores de Decisão:** Cada árvore de decisão é construída com base em um subconjunto aleatório de features em cada divisão do nó. Isso ajuda a garantir que cada árvore tenha um foco diferente no conjunto de dados.

**Votação para Classificação ou Média para Regressão:** No caso da classificação, cada árvore "vota" na classe prevista, e a classe mais votada se torna a predição final do Random Forest. Para regressão, a saída de cada árvore é média para obter a predição final.

**Propósito:**

- **Redução de Overfitting:** Ao criar várias árvores com amostras aleatórias e características, o Random Forest reduz o overfitting, tornando o modelo mais robusto e geral.

- **Lidando com Variáveis Importantes:** Ao calcular a importância de cada variável em todas as árvores, o Random Forest fornece uma medida de quão significativas são as features para o modelo.

- **Melhor Desempenho Geral:** Ao combinar as previsões de várias árvores, o Random Forest geralmente supera as limitações de uma única árvore de decisão, tornando-se uma escolha popular em uma variedade de tarefas de aprendizado de máquina.

### **Pré-processamento**

- Identificação das colunas não numéricas no DataFrame.

- Conversão da coluna 'bomb_planted' para o tipo de dado int16.

- Contagem da quantidade de ocorrências de cada valor na coluna 'round_winner'.

- Utilização do LabelEncoder para transformar colunas não numéricas em valores numéricos.

- Aplicação do RobustScaler a cada coluna, exceto 'round_winner', para escalonamento robusto.

- Separação dos dados em features (x) e rótulos (y), excluindo a coluna 'round_winner'.

- Inicialização e treinamento do modelo RandomForest com os dados de features e rótulos.

- Cálculo da importância de cada feature no modelo RandomForest.

- Obtenção dos índices que ordenam as features de acordo com sua importância.
"""

# Identificar colunas não numéricas
colunas_nao_numericas = data.select_dtypes(exclude=np.number).columns

# Imprimir as colunas não numéricas
print(colunas_nao_numericas)

# Converter 'bomb_planted' para int16
data['bomb_planted'] = data['bomb_planted'].astype(np.int16)

# Contar valores únicos em 'round_winner'
contagem_round_winner = data['round_winner'].value_counts()
print(contagem_round_winner)

# Inicializar LabelEncoder
lbl = LabelEncoder()

# Aplicar LabelEncoder a colunas não numéricas
for coluna in colunas_nao_numericas:
    data[coluna] = lbl.fit_transform(data[coluna])

# Converter 'bomb_planted' para int16 novamente (se necessário)
data['bomb_planted'] = data['bomb_planted'].astype(np.int16)

# Criar lista de colunas exceto 'round_winner'
cols = [col for col in data.columns if col != 'round_winner']

# Inicializar RobustScaler
scaler = RobustScaler()

# Aplicar RobustScaler a colunas exceto 'round_winner'
for col in cols:
    data[col] = scaler.fit_transform(data[[col]])

# Dividir os dados em features (x) e rótulos (y)
x = data.drop(['round_winner'], axis=1)
y = data['round_winner']

# Imprimir o número de colunas
print("Número de colunas:", len(cols))

# Exibir as primeiras linhas de x
print(x.head())

# Inicializar o modelo RandomForest
modelo = RandomForestClassifier()

# Treinar o modelo com os dados de features (x) e rótulos (y)
modelo.fit(x, y)

# Obter as importâncias das features
importancias = modelo.feature_importances_

# Obter os índices ordenados das importâncias
indices_ordenados = np.argsort(importancias)

indices_ordenados

"""### **Classificação**"""

# Criar um gráfico de barras horizontais para visualizar as importâncias das features
plt.figure(figsize=(10, 8))  # Ajustando o tamanho do gráfico para médio
plt.title('Importância das Features no Modelo RandomForest', fontsize=16)  # Adicionando um título e ajustando o tamanho da fonte
plt.barh(range(len(indices_ordenados)), importancias[indices_ordenados], align='center', color='blue', height=1)  # Ajustando o espaçamento entre as barras
plt.yticks(range(len(indices_ordenados)), [cols[i] for i in indices_ordenados], fontsize=7)  # Ajustando o tamanho da fonte no eixo y
plt.xlabel('Importância da Feature', fontsize=14)  # Ajustando o tamanho da fonte no eixo x
plt.ylabel('Features', fontsize=14)  # Adicionando um rótulo ao eixo y
plt.grid(axis='x', linestyle='--')  # Adicionando linhas de grade no eixo x para referência
plt.show()

# Definir o número máximo de features a serem exibidas no gráfico
numero_maximo_features = 40

# Criar um gráfico de barras horizontais para visualizar as importâncias das features
plt.figure(figsize=(15, 14))
plt.title(f'Top {numero_maximo_features} Features no Modelo RandomForest', fontsize=16)
plt.barh(range(numero_maximo_features), importancias[indices_ordenados][-numero_maximo_features:], align='center', color='gray', height=0.7)
plt.yticks(range(numero_maximo_features), [cols[i] for i in indices_ordenados][-numero_maximo_features:], fontsize=12)
plt.xlabel('Importância da Feature', fontsize=14)
plt.ylabel('Features', fontsize=14)
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.show()

"""A ordem das importâncias das features é calculada pelo algoritmo do modelo Random Forest. O Random Forest é um ensemble de árvores de decisão, e cada árvore no conjunto atribui importâncias às features com base em sua contribuição para a redução da impureza nos nós durante o processo de treinamento.

A métrica usada para calcular a importância de uma feature é geralmente a diminuição da impureza média ponderada (ou o ganho de informação) causada pela inclusão dessa feature nas decisões tomadas pelos nós das árvores.

Aqui estão os passos principais:

Calculo da Diminuição da Impureza:

Durante a construção de cada árvore de decisão, em cada nó, a árvore procura a feature que maximiza a diminuição da impureza. A impureza é uma medida de quão misturadas são as classes em um conjunto de dados.
Média Ponderada:

A diminuição da impureza é calculada para cada feature em cada nó. A importância total de uma feature é a média ponderada dessas diminuições em todos os nós da árvore, ponderada pelo número de amostras em cada nó.
Média nas Árvores:

No caso do Random Forest, que é um conjunto de árvores, a importância de cada feature é a média das importâncias em todas as árvores do conjunto.
Ordenação:

As features são então ordenadas de acordo com suas importâncias calculadas, em ordem decrescente. Isso forma a ordem que é utilizada para criar o gráfico das importâncias das features.
Assim, as features que mais contribuem para a redução da impureza nos nós durante a construção das árvores são consideradas mais importantes, e essa ordem é usada para destacar as features mais relevantes no gráfico.
"""

imp = np.argsort(importancias)[-40:]

imp_cols = [cols[i] for i in imp]

imp_cols

x = x[imp_cols]

x.shape

x.head()